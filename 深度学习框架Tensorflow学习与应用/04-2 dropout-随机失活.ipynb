{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595908803722",
   "display_name": "Python 3.5.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补充\n",
    "\n",
    "* 此代码容易炸，谨慎运行，耗时长(~30min)\n",
    "* dropout 只训练集使用\n",
    "` sess.run(train_step, feed_dict={x: batch_xs,y:batch_ys, keep_prob:1.0})`\n",
    "* 适合大数据集ImageNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep_prob:o.7\n",
    ">\n",
    "\n",
    "\n",
    "keep_prob:1.0\n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extracting ../MNIST_data\\train-images-idx3-ubyte.gz\nExtracting ../MNIST_data\\train-labels-idx1-ubyte.gz\nExtracting ../MNIST_data\\t10k-images-idx3-ubyte.gz\nExtracting ../MNIST_data\\t10k-labels-idx1-ubyte.gz\nIter0Training Accurancy0.91794544Testing Accurancy0.9222\nIter1Training Accurancy0.93194544Testing Accurancy0.9342\nIter2Training Accurancy0.94216365Testing Accurancy0.9411\nIter3Training Accurancy0.9476727Testing Accurancy0.9465\nIter4Training Accurancy0.95214546Testing Accurancy0.9488\nIter5Training Accurancy0.95494545Testing Accurancy0.9513\nIter6Training Accurancy0.95754546Testing Accurancy0.9535\nIter7Training Accurancy0.9597818Testing Accurancy0.9546\nIter8Training Accurancy0.9620364Testing Accurancy0.957\nIter9Training Accurancy0.96427274Testing Accurancy0.9581\nIter10Training Accurancy0.96596366Testing Accurancy0.9597\nIter11Training Accurancy0.9676727Testing Accurancy0.961\nIter12Training Accurancy0.96909094Testing Accurancy0.9632\nIter13Training Accurancy0.9702727Testing Accurancy0.9622\nIter14Training Accurancy0.97156364Testing Accurancy0.9657\nIter15Training Accurancy0.97243637Testing Accurancy0.9654\nIter16Training Accurancy0.9735818Testing Accurancy0.9668\nIter17Training Accurancy0.97481817Testing Accurancy0.9673\nIter18Training Accurancy0.97432727Testing Accurancy0.9658\nIter19Training Accurancy0.9761091Testing Accurancy0.9679\nIter20Training Accurancy0.9766909Testing Accurancy0.9699\n"
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True) \n",
    "# x相对路径  数据集下载到某一目录下（相对路径不懂可自行百度）\n",
    "# one-hot=True 把标签设置为one-hot 格式\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 整除\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # None 100？\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout  多少神经元在工作\n",
    "\n",
    "# 构建一个简单的神经网络\n",
    "# W = tf.Variable(tf.zeros([784,10]))\n",
    "# b = tf.Variable(tf.zeros([10]))\n",
    "# prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "# W1 = tf.Variable(tf.truncated_normal([784.2000], stddev=0.1))# 截断初始化 正态分布初始化W  标准差0.1  \n",
    "W1=tf.Variable(tf.truncated_normal([784,2000],stddev=0.1)) \n",
    "b1 = tf.Variable(tf.zeros([2000]) +0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([2000,1000], stddev=0.1)) # 2000神经元(想出现过拟合，然后dropout解决)\n",
    "b2 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2) + b2)\n",
    "L2_drop = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([1000,10], stddev=0.1)) # 2000神经元(想出现过拟合，然后dropout解决)\n",
    "b3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L2_drop,W3)+b3)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction)) \n",
    "# Iter20Testing Accurancy0.9134\n",
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "# Iter20Testing Accurancy0.9211\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# Iter20Testing Accurancy0.9223\n",
    "\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,axis=1)) # 相同为Ture，argmax 函数起的是1所在维度最大值的index索引  1表示axis第二个维度\n",
    "# 0表示按列查找  1表示按行查找（0列1行）\n",
    "\n",
    "# 求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # 布尔型列表转化为flaot32类型 True变为1.0，False变为0\n",
    "# 求平均值就得到准确率，比如10个值，9个True  1个False\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoth in range(21):\n",
    "         for batch in range(n_batch):\n",
    "             batch_xs, batch_ys = mnist.train.next_batch(batch_size) # 图片和标签\n",
    "             sess.run(train_step, feed_dict={x: batch_xs,y:batch_ys, keep_prob:0.7})\n",
    "         test_acc= sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels, keep_prob:1.0})\n",
    "         train_acc= sess.run(accuracy, feed_dict={x:mnist.train.images, y:mnist.train.labels, keep_prob: 1.0})\n",
    "         print(\"Iter\"+ str(epoth) +\"Training Accurancy\" + str(train_acc) +\"Testing Accurancy\" + str(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}