{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595906854696",
   "display_name": "Python 3.5.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补充\n",
    "笔记：https://www.yuque.com/huangzhongqing/tensorflow/yiggki\n",
    "\n",
    "\n",
    "修改交叉熵 对数似然\n",
    "```\n",
    "# 二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(y-prediction)) \n",
    "# Iter20Testing Accurancy0.9134\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "# Iter20Testing Accurancy0.9211\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# Iter20Testing Accurancy0.9223\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extracting ../MNIST_data\\train-images-idx3-ubyte.gz\nExtracting ../MNIST_data\\train-labels-idx1-ubyte.gz\nExtracting ../MNIST_data\\t10k-images-idx3-ubyte.gz\nExtracting ../MNIST_data\\t10k-labels-idx1-ubyte.gz\nIter0Testing Accurancy0.8276\nIter1Testing Accurancy0.8953\nIter2Testing Accurancy0.9021\nIter3Testing Accurancy0.9064\nIter4Testing Accurancy0.9086\nIter5Testing Accurancy0.9108\nIter6Testing Accurancy0.9121\nIter7Testing Accurancy0.9143\nIter8Testing Accurancy0.9152\nIter9Testing Accurancy0.9164\nIter10Testing Accurancy0.918\nIter11Testing Accurancy0.9176\nIter12Testing Accurancy0.9191\nIter13Testing Accurancy0.9186\nIter14Testing Accurancy0.92\nIter15Testing Accurancy0.9206\nIter16Testing Accurancy0.9209\nIter17Testing Accurancy0.9203\nIter18Testing Accurancy0.9211\nIter19Testing Accurancy0.9205\nIter20Testing Accurancy0.9223\n"
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data\", one_hot=True) \n",
    "# x相对路径  数据集下载到某一目录下（相对路径不懂可自行百度）\n",
    "# one-hot=True 把标签设置为one-hot 格式\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size  # 整除\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # None 100？\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 构建一个简单的神经网络\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "# # 构建一个复杂的的神经网络  失败\n",
    "# W = tf.Variable(tf.zeros([784,100]))\n",
    "# b = tf.Variable(tf.zeros([100]))\n",
    "# a1 = tf.nn.tanh(tf.matmul(x,W)+b)\n",
    "# W1 = tf.Variable(tf.zeros([100,10]))\n",
    "# b1 = tf.Variable(tf.zeros([10]))\n",
    "# prediction = tf.nn.softmax(tf.matmul(a1,W1)+b1)\n",
    "'''Iter3Testing Accurancy0.1135\n",
    "Iter4Testing Accurancy0.1135\n",
    "'''\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction)) \n",
    "# Iter20Testing Accurancy0.9134\n",
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "# Iter20Testing Accurancy0.9211\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# Iter20Testing Accurancy0.9223\n",
    "\n",
    "# 使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,axis=1)) # 相同为Ture，argmax 函数起的是1所在维度最大值的index索引  1表示axis第二个维度\n",
    "# 0表示按列查找  1表示按行查找（0列1行）\n",
    "\n",
    "# 求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # 布尔型列表转化为flaot32类型 True变为1.0，False变为0\n",
    "# 求平均值就得到准确率，比如10个值，9个True  1个False\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoth in range(21):\n",
    "         for batch in range(n_batch):\n",
    "             batch_xs, batch_ys = mnist.train.next_batch(batch_size) # 图片和标签\n",
    "             sess.run(train_step, feed_dict={x: batch_xs,y:batch_ys})\n",
    "         acc= sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "         print(\"Iter\"+ str(epoth) +\"Testing Accurancy\" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}